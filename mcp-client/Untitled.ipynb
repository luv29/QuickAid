{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70bab50f-3bb0-403e-995c-08c431625e3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 157\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m--> 157\u001b[0m     \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\LUV\\python\\Lib\\asyncio\\runners.py:186\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from typing import Optional\n",
    "from contextlib import AsyncExitStack\n",
    "import json\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # load environment variables from .env\n",
    "\n",
    "class MCPClient:\n",
    "    def __init__(self):\n",
    "        # Initialize session and client objects\n",
    "        self.session: Optional[ClientSession] = None\n",
    "        self.exit_stack = AsyncExitStack()\n",
    "        self.anthropic = OpenAI()\n",
    "    \n",
    "    async def connect_to_server(self, server_script_path: str):\n",
    "        \"\"\"Connect to an MCP server\n",
    "\n",
    "        Args:\n",
    "            server_script_path: Path to the server script (.py or .js)\n",
    "        \"\"\"\n",
    "        is_python = server_script_path.endswith('.py')\n",
    "        is_js = server_script_path.endswith('.js')\n",
    "        if not (is_python or is_js):\n",
    "            raise ValueError(\"Server script must be a .py or .js file\")\n",
    "\n",
    "        command = \"python\" if is_python else \"node\"\n",
    "        server_params = StdioServerParameters(\n",
    "            command=command,\n",
    "            args=[server_script_path],\n",
    "            env=None\n",
    "        )\n",
    "\n",
    "        stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))\n",
    "        self.stdio, self.write = stdio_transport\n",
    "        self.session = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write))\n",
    "\n",
    "        await self.session.initialize()\n",
    "\n",
    "        # List available tools\n",
    "        response = await self.session.list_tools()\n",
    "        tools = response.tools\n",
    "        print(\"\\nConnected to server with tools:\", [tool.name for tool in tools])\n",
    "    \n",
    "    async def process_query(self, query: str) -> str:\n",
    "        \"\"\"Process a query using Claude and available tools\"\"\"\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = await self.session.list_tools()\n",
    "        available_tools = [{\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": tool.name,\n",
    "                \"description\": tool.description,\n",
    "                \"parameters\": tool.inputSchema\n",
    "            }\n",
    "        } for tool in response.tools]\n",
    "\n",
    "        # print(available_tools)\n",
    "\n",
    "        # Initial Claude API call\n",
    "        response = self.anthropic.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            max_tokens=1000,\n",
    "            messages=messages,\n",
    "            tools=available_tools\n",
    "        )\n",
    "\n",
    "        # Process response and handle tool calls\n",
    "        final_text = []\n",
    "        final_text.append(response.choices[0].message.content)\n",
    "\n",
    "        assistant_message_content = []\n",
    "        for content in response.choices[0].message.tool_calls or []:\n",
    "            tool_name = content.function.name\n",
    "            tool_args = json.loads(content.function.arguments)\n",
    "\n",
    "            # Execute tool call\n",
    "            print(f\"[Calling tool {tool_name} with args {tool_args}]\")\n",
    "            result = await self.session.call_tool(tool_name, tool_args)\n",
    "            final_text.append(f\"[Calling tool {tool_name} with args {tool_args}]\")\n",
    "\n",
    "            assistant_message_content.append(content)\n",
    "            messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": assistant_message_content\n",
    "            })\n",
    "            messages.append({\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"tool_result\",\n",
    "                        \"tool_use_id\": content.id,\n",
    "                        \"content\": result.content\n",
    "                    }\n",
    "                ]\n",
    "            })\n",
    "            print(messages)\n",
    "\n",
    "            # Get next response from Claude\n",
    "            response = self.anthropic.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                max_tokens=1000,\n",
    "                messages=messages,\n",
    "                tools=available_tools\n",
    "            )\n",
    "\n",
    "            final_text.append(response.choices[0].message.content)\n",
    "\n",
    "        return \"\\n\".join(final_text)\n",
    "\n",
    "    async def chat_loop(self):\n",
    "        \"\"\"Run an interactive chat loop\"\"\"\n",
    "        print(\"\\nMCP Client Started!\")\n",
    "        print(\"Type your queries or 'quit' to exit.\")\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                query = input(\"\\nQuery: \").strip()\n",
    "\n",
    "                if query.lower() == 'quit':\n",
    "                    break\n",
    "\n",
    "                response = await self.process_query(query)\n",
    "                print(\"\\n\" + response)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\nError: {str(e)}\")\n",
    "\n",
    "    async def cleanup(self):\n",
    "        \"\"\"Clean up resources\"\"\"\n",
    "        await self.exit_stack.aclose()\n",
    "\n",
    "async def main():\n",
    "    # if len(sys.argv) < 2:\n",
    "    #     print(\"Usage: python client.py <path_to_server_script>\")\n",
    "    #     sys.exit(1)\n",
    "\n",
    "    client = MCPClient()\n",
    "    try:\n",
    "        await client.connect_to_server(\"../mcp-server/build/index.js\")\n",
    "        await client.chat_loop()\n",
    "    finally:\n",
    "        await client.cleanup()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86209a65-2585-46cd-86b9-0c618a719e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mcp\n",
      "  Downloading mcp-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: anyio>=4.5 in c:\\luv\\python\\lib\\site-packages (from mcp) (4.8.0)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in c:\\luv\\python\\lib\\site-packages (from mcp) (0.4.0)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\luv\\python\\lib\\site-packages (from mcp) (0.27.0)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in c:\\luv\\python\\lib\\site-packages (from mcp) (2.7.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.2 in c:\\luv\\python\\lib\\site-packages (from mcp) (2.10.4)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in c:\\luv\\python\\lib\\site-packages (from mcp) (2.1.3)\n",
      "Requirement already satisfied: starlette>=0.27 in c:\\luv\\python\\lib\\site-packages (from mcp) (0.45.3)\n",
      "Requirement already satisfied: uvicorn>=0.23.1 in c:\\luv\\python\\lib\\site-packages (from mcp) (0.34.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\luv\\python\\lib\\site-packages (from anyio>=4.5->mcp) (3.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\luv\\python\\lib\\site-packages (from anyio>=4.5->mcp) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in c:\\luv\\python\\lib\\site-packages (from anyio>=4.5->mcp) (4.12.2)\n",
      "Requirement already satisfied: certifi in c:\\luv\\python\\lib\\site-packages (from httpx>=0.27->mcp) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\luv\\python\\lib\\site-packages (from httpx>=0.27->mcp) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\luv\\python\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->mcp) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\luv\\python\\lib\\site-packages (from pydantic<3.0.0,>=2.7.2->mcp) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\luv\\python\\lib\\site-packages (from pydantic<3.0.0,>=2.7.2->mcp) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\luv\\python\\lib\\site-packages (from pydantic-settings>=2.5.2->mcp) (1.0.1)\n",
      "Requirement already satisfied: click>=7.0 in c:\\luv\\python\\lib\\site-packages (from uvicorn>=0.23.1->mcp) (8.1.7)\n",
      "Requirement already satisfied: colorama in c:\\luv\\python\\lib\\site-packages (from click>=7.0->uvicorn>=0.23.1->mcp) (0.4.6)\n",
      "Downloading mcp-1.6.0-py3-none-any.whl (76 kB)\n",
      "Installing collected packages: mcp\n",
      "Successfully installed mcp-1.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install mcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d984d032-9906-4e05-a14d-1f354ba69bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
